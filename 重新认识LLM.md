Chain-of-Thought   推理（ 扩展提示词 <think> </think>   =>  DS-R1模型 )      Google Big Brain的论文
实际上用V3更好      DeepSeek-V3-Base => RLHF(Reinforcement Learning with Humans Feedback) => DeepSeek-V3
    */             DeepSeek-V3-Base => Cot => DeepSeek-R1

deepclaude github: https://github.com/deepclaude  解释为什么用V3更好的东西

商业化上小心思  R1收更多钱  因为算上了思维过程(Cot)

怎么使用大模型玩出花

there an ai for that  AI导航站
theresanaiforthat.com

Monica  拆解网站

monica.im/home 套壳别人的API

Trae?  字节

https://metaso.cn/  米塔AI 三方网站
siliconflow
chatbox


生命,宇宙以及任何事情的终极答案是42 :)😁
Answer to the Ultimate Question of Life, the Universe, and Everything

大预言模型只做一件事    输入提示词    输出下一个token的概率

NextToken Prediction /  Autoregressive 大模型泛式 短期不会变


提示词是  人类与大模型交互的唯一接口





丹特丽安的书架 ???????????

会议讨论了大模型相关诸多话题，包括工作机制、训练原理、幻觉问题及商业化等。主要内容包括：

大模型相关话题分享

大模型使用疑问：包括应用形式、提示词含义、模型幻觉、推理模型等方面的疑问。
大模型思考方式：中短期下一个token预测和自回归的大模型范式不会改变，大模型输入提示词输出下一个词的概率分布。
模型与产品区分：GPT4O、DeepSeek V3等是模型，ChatGPT、DeepSIG是基于模型构建的产品。
大模型幻觉：探讨了大模型幻觉的概念及能否避免。
热门技术与应用：介绍了DiffSIG的出圈原因及DPCR1模型，还提及世界各地使用大模型的情况和相关案例。
大语言模型的工作机制与幻觉现象

上下文缓存功能：将上一轮的输入和输出缓存，与新的提示词拼在一起输入大模型，这是产品侧的功能，并非大模型本身具备。
联网搜索功能：先通过提示词调用搜索引擎获取结果，处理后与提示词拼在一起输入大模型。
大模型工作机制：大模型接收提示词，计算下一个词的概率分布，且不知道输入词的来源，无状态。
输出结果机制：通过循环采样，直到采样到表示句子结束的特殊token才停止输出。
幻觉现象本质：由于计算概率分布时未按人类预期输出，错误连锁反应导致输出跑偏，被人类认为是幻觉。
大语言模型的训练原理与提示词工程

模型训练流程：输入数据给模型，计算输出与真实值的差距，模型根据差距调整参数，重复此过程使模型越来越准。
数据需求与标注：模型训练需要大量成对的标注数据，人工标注成本高，且以往模型对训练数据十分贪婪。
解决数据问题：从模型侧解决数据问题，利用人类文本构建训练数据，古往今来人类所有的文本都可用于训练，使模型效果更好。
自回归模型：自回归模型能将输入数据逐步训练进模型，训练完后再次输入，输出会向训练数据靠近。
提示词工程：探讨了提示词工程中如何写提示词及背后的支撑内容。
关于提示词和DeepSeek模型的讨论

提示词技巧：提示词是人类与大模型交互的唯一接口，写提示词的唯一技巧是写长一点，写得越长越详细，大模型能注意到的正确提示词就越多，越利于输出满足需求的内容。
DeepSeek模型出圈原因：进入视野时打出百万token一块钱的slogan，性价比高；靠模型创新，如MLA加DeepSeek、多头潜在注意力机制、MOE架构和超强Infra，其发明的MLA注意力机制能降低训练和推理成本。
大模型的幻觉问题及解决办法

大模型幻觉现象：大模型在判断如数字比较、单词字母计数等简单问题时会出错，原因是输入信息在处理前就有损失，机器难以像人类大脑那样理解整体概念。
降低成本与开源：降低大模型的训练和推理成本能提高利润空间，朴实物华的开源风格受开发者欢迎，促进了模型的传播。
思维链解决办法：谷歌大脑团队发表的论文提出思维链方法，即把要解决的问题按逻辑拆解后作为示例输入大模型，能提高回答的准确性，DeepSeek R1和ChatGPT的O1是对该论文的实现。
关于大模型推理模型及商业化的探讨

推理模型实现方式：模型层面实现了O1和R1推理模型，通过后训练方式强迫输出过程以提升某些问题的准确性，如R1模型会生成sync内容来扩展提示词。
推理模型存在矛盾：某些问题需要更多详细提示词才能做对，但给出详细步骤让模型做对会使整个过程失去意义。
模型训练特点：预训练模型要通过后训练来符合人类意图，如DC3 BASE模型经思维链训练和人类反馈强化学习后变成Deepseek V3。
模型效果对比：在提示词写得好的情况下，Deepseek V3与Deepseek R1效果一样，如deep cloud项目将R1的思考部分与问题拼起放入模型推理效果更好。
商业化价格策略：Deepseek API文档显示价格变化，R1和V3推理成本相同但R1价格更高，利用人们认为R1更好的心理获取更多利润。
关于AI模型的探讨与思考

R1模型性价比低：R1模型在思维链过程中产生的费用较高，性价比不如V3模型，导致其在商业化应用中存在问题，影响了开发者的选择和公司的负载均衡。
AI导航网站推荐：推荐了JIRS AI for that和model卡等网站，前者是流量最大的AI导航站，后者是套壳工具站，可从中获取灵感和了解赚钱方式。
大模型能力边界：大模型不能超越人类知识的边界，无法回答诸如生命宇宙的终极问题，更像压缩人类知识的图书馆，能帮助人类探索未知，但不是神明。
关于大模型的探讨

大模型部署不易：Deepseek 模型仅提供中间红色部分，要将其部署起来面临诸多困难，如联网、R1 等方面。
提示词的作用：提示词是人类与大模型交互的唯一接口，Deepseek 可将提示词扩展部分压缩到模型里优化幻觉问题，而普通用户无法做到。
大模型的本质：大模型类似压缩了人类知识的图书馆，不是神，应立足自身能力利用其扩展能力实现目标。
大模型应用案例：产品经理利用大模型写代码和完成APP上架，登上大陆免费榜第一名。
大模型训练问题：模型太大，数据量少，无法训练，写代码是大模型擅长的工作。
模型部署的差异：部署的主要区别在于缓存、提示词模板、搜索内容抽取、token转换、用户界面等方面。
开源与商业化：Deepseek开源是一种商业化策略，不会影响自身商业化API服务，其推理成本和Infra能力有优势，掌握定价权。


会议讨论了大模型相关诸多话题，包括工作机制、训练原理、幻觉问题及商业化等。主要内容包括：

大模型相关话题分享

大模型使用疑问：包括应用形式、提示词含义、模型幻觉、推理模型等方面的疑问。
大模型思考方式：中短期下一个token预测和自回归的大模型范式不会改变，大模型输入提示词输出下一个词的概率分布。
模型与产品区分：GPT4O、DeepSeek V3等是模型，ChatGPT、DeepSIG是基于模型构建的产品。
大模型幻觉：探讨了大模型幻觉的概念及能否避免。
热门技术与应用：介绍了DiffSIG的出圈原因及DPCR1模型，还提及世界各地使用大模型的情况和相关案例。
大语言模型的工作机制与幻觉现象

上下文缓存功能：将上一轮的输入和输出缓存，与新的提示词拼在一起输入大模型，这是产品侧的功能，并非大模型本身具备。
联网搜索功能：先通过提示词调用搜索引擎获取结果，处理后与提示词拼在一起输入大模型。
大模型工作机制：大模型接收提示词，计算下一个词的概率分布，且不知道输入词的来源，无状态。
输出结果机制：通过循环采样，直到采样到表示句子结束的特殊token才停止输出。
幻觉现象本质：由于计算概率分布时未按人类预期输出，错误连锁反应导致输出跑偏，被人类认为是幻觉。
大语言模型的训练原理与提示词工程

模型训练流程：输入数据给模型，计算输出与真实值的差距，模型根据差距调整参数，重复此过程使模型越来越准。
数据需求与标注：模型训练需要大量成对的标注数据，人工标注成本高，且以往模型对训练数据十分贪婪。
解决数据问题：从模型侧解决数据问题，利用人类文本构建训练数据，古往今来人类所有的文本都可用于训练，使模型效果更好。
自回归模型：自回归模型能将输入数据逐步训练进模型，训练完后再次输入，输出会向训练数据靠近。
提示词工程：探讨了提示词工程中如何写提示词及背后的支撑内容。
关于提示词和DeepSeek模型的讨论

提示词技巧：提示词是人类与大模型交互的唯一接口，写提示词的唯一技巧是写长一点，写得越长越详细，大模型能注意到的正确提示词就越多，越利于输出满足需求的内容。
DeepSeek模型出圈原因：进入视野时打出百万token一块钱的slogan，性价比高；靠模型创新，如MLA加DeepSeek、多头潜在注意力机制、MOE架构和超强Infra，其发明的MLA注意力机制能降低训练和推理成本。
大模型的幻觉问题及解决办法

大模型幻觉现象：大模型在判断如数字比较、单词字母计数等简单问题时会出错，原因是输入信息在处理前就有损失，机器难以像人类大脑那样理解整体概念。
降低成本与开源：降低大模型的训练和推理成本能提高利润空间，朴实物华的开源风格受开发者欢迎，促进了模型的传播。
思维链解决办法：谷歌大脑团队发表的论文提出思维链方法，即把要解决的问题按逻辑拆解后作为示例输入大模型，能提高回答的准确性，DeepSeek R1和ChatGPT的O1是对该论文的实现。
关于大模型推理模型及商业化的探讨

推理模型实现方式：模型层面实现了O1和R1推理模型，通过后训练方式强迫输出过程以提升某些问题的准确性，如R1模型会生成sync内容来扩展提示词。
推理模型存在矛盾：某些问题需要更多详细提示词才能做对，但给出详细步骤让模型做对会使整个过程失去意义。
模型训练特点：预训练模型要通过后训练来符合人类意图，如DC3 BASE模型经思维链训练和人类反馈强化学习后变成Deepseek V3。
模型效果对比：在提示词写得好的情况下，Deepseek V3与Deepseek R1效果一样，如deep cloud项目将R1的思考部分与问题拼起放入模型推理效果更好。
商业化价格策略：Deepseek API文档显示价格变化，R1和V3推理成本相同但R1价格更高，利用人们认为R1更好的心理获取更多利润。
关于AI模型的探讨与思考

R1模型性价比低：R1模型在思维链过程中产生的费用较高，性价比不如V3模型，导致其在商业化应用中存在问题，影响了开发者的选择和公司的负载均衡。
AI导航网站推荐：推荐了JIRS AI for that和model卡等网站，前者是流量最大的AI导航站，后者是套壳工具站，可从中获取灵感和了解赚钱方式。
大模型能力边界：大模型不能超越人类知识的边界，无法回答诸如生命宇宙的终极问题，更像压缩人类知识的图书馆，能帮助人类探索未知，但不是神明。
关于大模型的探讨

大模型部署不易：DeepSeek模型只有中间部分，部署需考虑诸多因素，如R1、联网等，并非简单认为已有相关能力就能轻易完成。
提示词是交互接口：提示词是人类与大模型交互的唯一接口，大模型创作者优化模型幻觉问题也常从提示词入手。
大模型并非万能：大模型类似压缩知识的图书馆，不是神，应立足自身能力借助其扩展能力实现目标。
大模型应用案例：以小猫补光灯为例，产品经理利用大模型写代码和完成APP上架，展示普通人借助大模型扩展能力获取成果。
大模型训练与应用：模型太大数据量少难以训练，写代码是大模型擅长的工作，部署的差异体现在缓存、搜索、提示词模板等方面。
开源模型的影响：DeepSeek开源是一种商业化策略，不会影响自身商业化API服务，第三方部署在推理效率和成本等方面难以竞争。
国内模型开发情况：有实力的公司会独立训练大模型，部分公司基于开源模型如LLAMA进行二次开发。